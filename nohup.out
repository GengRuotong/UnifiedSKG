train_prefix_tuning_multi_expert.sh: 8: train_prefix_tuning_multi_expert.sh: 
export WANDB_API_KEY=3b9858e8352beadda80313599d455c2abfde4ba7
export WANDB_PROJECT=T5_base_prefix_tuning_explore
export WANDB_ENTITY=ruotonggeng
: not found
/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/torch/__init__.py:422: UserWarning: torch.set_deterministic is deprecated and will be removed in a future release. Please use torch.use_deterministic_algorithms instead
  "torch.set_deterministic is deprecated and will be removed in a future "
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/torch/__init__.py:422: UserWarning: torch.set_deterministic is deprecated and will be removed in a future release. Please use torch.use_deterministic_algorithms instead
  "torch.set_deterministic is deprecated and will be removed in a future "
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
INFO:root:Added key: store_based_barrier_key:1 to store for rank: 0
INFO:root:Added key: store_based_barrier_key:1 to store for rank: 1
task_args.bert.location: pretrained_model/chinese_t5_pegasus_base/
WARNING:datasets.builder:Using custom data configuration default
WARNING:datasets.builder:Reusing dataset mt_summary (./data/cache/maicai/mt_summary/default/0.0.0/fcbcb55d759d91f94583fb1e4e71a20b93adb0824af65f5974e85039af27cbb8)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 1608.66it/s]
task_args.bert.location: pretrained_model/chinese_t5_pegasus_base/
WARNING:datasets.builder:Using custom data configuration default
WARNING:datasets.builder:Reusing dataset mt_summary (./data/cache/maoyanyanchu/mt_summary/default/0.0.0/9a2a8301897229a50ff06132e89e5dbba56c45787624052d1519745b9e9e1887)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 1259.30it/s]
task_args.bert.location: pretrained_model/chinese_t5_pegasus_base/
WARNING:datasets.builder:Using custom data configuration default
WARNING:datasets.builder:Reusing dataset mt_summary (./data/cache/taxi-yonghu/mt_summary/default/0.0.0/fa920e0494a7f0d0ecba1219a51e859ae5703519479b7c196820117d004344f4)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 1864.14it/s]
Before upsampling {'META_TUNING/mt_maicai.cfg': 16659, 'META_TUNING/mt_maoyanyanchu.cfg': 8695, 'META_TUNING/mt_taxi-yonghu.cfg': 25006}
Upsampling weights {'META_TUNING/mt_maicai.cfg': 1.2251736543128413, 'META_TUNING/mt_maoyanyanchu.cfg': 1.6958495490246088, 'META_TUNING/mt_taxi-yonghu.cfg': 1.0}
After upsampling {'META_TUNING/mt_maicai.cfg': 20410, 'META_TUNING/mt_maoyanyanchu.cfg': 14745, 'META_TUNING/mt_taxi-yonghu.cfg': 25006}
decoder mat
prefix-tuning sequence length is 30.
The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'T5Tokenizer'. 
The class this function is called from is 'T5PegasusTokenizer'.
wandb: Currently logged in as: ruotonggeng (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.13.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: ERROR Error while calling W&B API: project not found (<Response [404]>)
Trainer for Chinese build successfully.
Thread SenderThread:
Traceback (most recent call last):
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/lib/retry.py", line 102, in __call__
    result = self._call_fn(*args, **kwargs)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/internal/internal_api.py", line 136, in execute
    six.reraise(*sys.exc_info())
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/six.py", line 719, in reraise
    raise value
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/internal/internal_api.py", line 130, in execute
    return self.client.execute(*args, **kwargs)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/vendor/gql-0.2.0/gql/client.py", line 52, in execute
    result = self._get_result(document, *args, **kwargs)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/vendor/gql-0.2.0/gql/client.py", line 60, in _get_result
    return self.transport.execute(document, *args, **kwargs)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py", line 39, in execute
    request.raise_for_status()
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/requests/models.py", line 953, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://api.wandb.ai/graphql

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/apis/normalize.py", line 24, in wrapper
    return func(*args, **kwargs)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/internal/internal_api.py", line 1087, in upsert_run
    response = self.gql(mutation, variable_values=variable_values, **kwargs)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/lib/retry.py", line 118, in __call__
    if not check_retry_fn(e):
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/util.py", line 809, in no_retry_auth
    raise CommError("Permission denied, ask the project owner to grant you access")
wandb.errors.CommError: Permission denied, ask the project owner to grant you access

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/internal/internal_util.py", line 52, in run
    self._run()
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/internal/internal_util.py", line 102, in _run
    self._process(record)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/internal/internal.py", line 290, in _process
    self._sm.send(record)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/internal/sender.py", line 184, in send
    send_handler(record)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/internal/sender.py", line 623, in send_run
    self._init_run(run, config_value_dict)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/internal/sender.py", line 659, in _init_run
    commit=repo.last_commit,
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/apis/normalize.py", line 62, in wrapper
    six.reraise(CommError, CommError(message, err), sys.exc_info()[2])
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/six.py", line 718, in reraise
    raise value.with_traceback(tb)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/apis/normalize.py", line 24, in wrapper
    return func(*args, **kwargs)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/internal/internal_api.py", line 1087, in upsert_run
    response = self.gql(mutation, variable_values=variable_values, **kwargs)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/lib/retry.py", line 118, in __call__
    if not check_retry_fn(e):
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/util.py", line 809, in no_retry_auth
    raise CommError("Permission denied, ask the project owner to grant you access")
wandb.errors.CommError: Permission denied, ask the project owner to grant you access
wandb: ERROR Internal wandb error: file data was not synced
Problem at: train.py 77 main
Traceback (most recent call last):
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/wandb_init.py", line 775, in init
    run = wi.init()
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/wandb_init.py", line 531, in init
    backend.cleanup()
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/backend/backend.py", line 167, in cleanup
    self.interface.join()
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 830, in join
    _ = self._communicate(record)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 539, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 544, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
wandb: ERROR Abnormal program exit
Traceback (most recent call last):
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/wandb_init.py", line 775, in init
    run = wi.init()
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/wandb_init.py", line 531, in init
    backend.cleanup()
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/backend/backend.py", line 167, in cleanup
    self.interface.join()
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 830, in join
    _ = self._communicate(record)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 539, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 544, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "train.py", line 309, in <module>
    main()
  File "train.py", line 77, in main
    **init_args,
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/wandb/sdk/wandb_init.py", line 812, in init
    six.raise_from(Exception("problem"), error_seen)
  File "<string>", line 3, in raise_from
Exception: problem
Traceback (most recent call last):
  File "train.py", line 309, in <module>
    main()
  File "train.py", line 249, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/transformers/trainer.py", line 1159, in train
    model = self._wrap_model(self.model_wrapped)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/transformers/trainer.py", line 995, in _wrap_model
    find_unused_parameters=find_unused_parameters,
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 446, in __init__
    self._sync_params_and_buffers(authoritative_rank=0)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 460, in _sync_params_and_buffers
    authoritative_rank)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 1156, in _distributed_broadcast_coalesced
    self.process_group, tensors, buffer_size, authoritative_rank
RuntimeError: Connection reset by peer
Traceback (most recent call last):
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/disk1/grt2021/anaconda3/envs/py3.7pytorch1.8new/bin/python', '-u', 'train.py', '--local_rank=1', '--run_name', 'mt_multi_prefix_phm_expert8_de_split_xmoe_mat12_phm16', '--local_rank', '-1', '--seed', '3407', '--cfg', 'Salesforce/T5_base_prefix_summary_3domains_upsample2_res_expert.cfg', '--pretrained_model_path', 'pretrained_model/chinese_t5_pegasus_base/', '--freeze_plm', 'True', '--data_folder_path', 'data/sample_datas_wo_prefix', '--output_dir', 'output/T5_base_prefix_tuning/multi_domain_prefix_phm_expert8_de_split_xmoe_mat12', '--do_train', '--do_eval', '--do_predict', '--overwrite_output_dir', '--num_train_epochs', '50', '--gradient_accumulation_steps', '2', '--logging_strategy', 'steps', '--logging_first_step', 'true', '--logging_steps', '100', '--evaluation_strategy', 'steps', '--eval_steps', '1000', '--metric_for_best_model', 'avr', '--greater_is_better', 'true', '--save_strategy', 'steps', '--save_steps', '1000', '--save_total_limit', '1', '--load_best_model_at_end', '--adafactor', 'true', '--learning_rate', '1e-3', '--per_device_train_batch_size', '4', '--per_device_eval_batch_size', '16', '--generation_num_beams', '1', '--generation_max_length', '128', '--input_max_length', '512', '--num_beams=1']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 28498
Killing subprocess 28499

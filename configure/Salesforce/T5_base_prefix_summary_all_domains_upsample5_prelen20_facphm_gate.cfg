[model]
name = unified.prefixtuning_phm_gate
use_description = True
concatenate_description = True
# Should be one of (separate, concatenate)
knowledge_usage = concatenate
freeze_plm = True
freeze_prefix = False
phm_dim = 4
factorized_phm=True
kronecker_prod_gate=True

[dataset]
data_store_path = ./data/cache
upsample_temp = 5

[seq2seq]
constructor = seq2seq_construction.meta_tuning
patience = 200

[arg_paths]
mt_maoyanyanchu = META_TUNING/mt_maoyanyanchu.cfg
mt_maicai = META_TUNING/mt_maicai.cfg
mt_waimai = META_TUNING/mt_waimai.cfg
mt_taxi-yonghu = META_TUNING/mt_taxi-yonghu.cfg
mt_youxuan = META_TUNING/mt_youxuan.cfg


[evaluate]
tool = metrics.meta_tuning.evaluator

[prefix_tuning]
prefix_sequence_length = 20
mid_dim = 512
prefix_dropout = 0.0

[special_tokens]
# less = ' <'
# less_or_equal = ' <='

unk_token = '[UNK]'
sep_token = '[SEP]'
pad_token = '[PAD]'
cls_token = '[CLS]'
mask_token = '[MASK]'

[bert]
description = t5-pegasus
location = pretrained_model/chinese_t5_pegasus_base/
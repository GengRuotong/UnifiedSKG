[model]
name = unified.finetune
# TODO
use_description = False
# TODO
concatenate_description = False
# Should be one of (separate, concatenate)
knowledge_usage = concatenate

[dataset]
data_store_path = ./data
# TODO
#eval_num = 500
# Larger upsample_temp leads to more uniform sampling
upsample_temp = 2

[seq2seq]
constructor = seq2seq_construction.meta_tuning

[arg_paths]
mt_maoyanyanchu = META_TUNING/mt_maoyanyanchu.cfg
mt_maicai = META_TUNING/mt_maicai.cfg
mt_waimai = META_TUNING/mt_waimai.cfg
mt_taxi-yonghu = META_TUNING/mt_taxi-yonghu.cfg
mt_youxuan = META_TUNING/mt_youxuan.cfg
mt_multi = META_TUNING/mt_multi.cfg

[evaluate]
tool = metrics.meta_tuning.evaluator

[special_tokens]
unk_token = '[UNK]'
sep_token = '[SEP]'
pad_token = '[PAD]'
cls_token = '[CLS]'
mask_token = '[MASK]'

[bert]
#location = tscholak/t5.1.1.lm100k.large
description = t5-pegasus
location = pretrained_model/chinese_t5_pegasus_base/
[model]
name = unified.combined_prefixtuning
use_description = True
concatenate_description = True
# Should be one of (separate, concatenate)
knowledge_usage = concatenate
freeze_plm = True

# params for multi-task prefix
freeze_task_specific_prefix = False
freeze_task_new_prefix = False
# Should be one of ["simple_separate", "separate_with_new_prefix", "simple_concat", "concat_with_new_prefix"]
prefix_agg_strategy = simple_concat


[dataset]
data_store_path = ./data/cache
upsample_temp = 2

[seq2seq]
constructor = seq2seq_construction.meta_tuning
patience = 300
threshold = 0.1

[arg_paths]
mt_maoyanyanchu = META_TUNING/mt_maoyanyanchu.cfg
mt_maicai = META_TUNING/mt_maicai.cfg
# mt_waimai = META_TUNING/mt_waimai.cfg
mt_taxi-yonghu = META_TUNING/mt_taxi-yonghu.cfg
# mt_youxuan = META_TUNING/mt_youxuan.cfg


[evaluate]
tool = metrics.meta_tuning.evaluator

[prefix_tuning]
prefix_sequence_length = 10
mid_dim = 128
prefix_dropout = 0.0

[special_tokens]
# less = ' <'
# less_or_equal = ' <='

unk_token = '[UNK]'
sep_token = '[SEP]'
pad_token = '[PAD]'
cls_token = '[CLS]'
mask_token = '[MASK]'

[bert]
description = t5-pegasus
location = pretrained_model/chinese_t5_pegasus_base/